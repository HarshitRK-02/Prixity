<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pixrity Voice Agent</title>
    <style>
        body { font-family: 'Segoe UI', sans-serif; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; background-color: #f0f2f5; margin: 0; }
        .container { background: white; padding: 2rem; border-radius: 12px; box-shadow: 0 10px 25px rgba(0,0,0,0.1); text-align: center; width: 400px; }
        button { padding: 12px 24px; font-size: 16px; background-color: #007bff; color: white; border: none; border-radius: 8px; cursor: pointer; transition: all 0.2s; margin: 5px; font-weight: 600; }
        button:hover { background-color: #0056b3; transform: translateY(-1px); }
        button:disabled { background-color: #ccc; cursor: not-allowed; transform: none; }
        #status { margin-top: 20px; color: #666; font-weight: bold; min-height: 1.2em; padding: 10px; border-radius: 4px; }
        .visualizer { height: 50px; background: #e9ecef; margin-top: 20px; border-radius: 4px; display: flex; align-items: center; justify-content: center; font-size: 0.9rem; color: #555; }
        .debug-info { margin-top: 20px; font-size: 12px; color: #999; text-align: left; background: #f8f9fa; padding: 10px; border-radius: 4px; border: 1px solid #eee; display: none;}
    </style>
</head>
<body>

<div class="container">
    <h2>AI Voice Agent</h2>
    <p>Powered by Pipecat, Deepgram & Groq</p>
    
    <button id="startBtn" onclick="startCall()">Start Conversation</button>
    <button id="stopBtn" onclick="stopCall()" disabled style="background-color: #dc3545; display: none;">End Call</button>

    <div id="status">Ready to connect...</div>

    <div class="visualizer" id="visualizer">
        (Microphone Inactive)
    </div>
    
    <div id="debug" class="debug-info"></div>
</div>

<script>
    let websocket;
    let audioContext;
    let processor;
    let inputSource;
    let keepErrorOnScreen = false;

    function logStatus(message, isError = false) {
        // If we have a critical error, don't overwrite it with "Disconnected"
        if (keepErrorOnScreen && !isError && message === "Disconnected") return;

        const statusDiv = document.getElementById('status');
        statusDiv.innerText = message;
        statusDiv.style.backgroundColor = isError ? "#ffebee" : "transparent";
        statusDiv.style.color = isError ? "#c62828" : "#666";
        console.log(`[Status] ${message}`);
        
        if (isError) keepErrorOnScreen = true;
    }

    function debugLog(msg) {
        const d = document.getElementById('debug');
        d.style.display = 'block';
        d.innerHTML += `<div>${msg}</div>`;
        console.log(`[Debug] ${msg}`);
    }

    async function startCall() {
        keepErrorOnScreen = false;
        document.getElementById('debug').innerHTML = "";
        logStatus("Connecting to server...");
        document.getElementById('startBtn').disabled = true;

        try {
            websocket = new WebSocket("ws://localhost:8765/ws");
            websocket.binaryType = "arraybuffer";

            websocket.onopen = async () => {
                logStatus("Server Connected! Starting Mic...");
                debugLog("WebSocket Open");
                document.getElementById('stopBtn').style.display = "inline-block";
                document.getElementById('stopBtn').disabled = false;
                await startAudioStream();
            };

            websocket.onmessage = (event) => {
                playAudioQueue(event.data);
            };

            websocket.onclose = (event) => {
                debugLog(`WebSocket Closed. Code: ${event.code}, Reason: ${event.reason || 'None'}`);
                if (event.code === 1006) {
                    logStatus("Error: Server closed connection unexpectedly. Check Python terminal for crash.", true);
                } else {
                    stopCall();
                }
            };

            websocket.onerror = (err) => {
                debugLog("WebSocket Error occurred");
                logStatus("Connection Failed. Is the server running?", true);
            };
        } catch (e) {
            logStatus("Init Error: " + e.message, true);
            document.getElementById('startBtn').disabled = false;
        }
    }

    async function startAudioStream() {
        try {
            // SAFE AUDIO CONTEXT SETUP
            // 1. Try to force 16kHz (best for VAD/Pipecat)
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
            } catch (e) {
                debugLog("16kHz Context not supported, falling back to native.");
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }

            debugLog(`Audio Sample Rate: ${audioContext.sampleRate}Hz`);

            if (audioContext.state === 'suspended') {
                await audioContext.resume();
            }

            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    channelCount: 1,
                    echoCancellation: true,
                    noiseSuppression: true,
                    sampleRate: 16000 // Hint to browser
                } 
            });
            
            logStatus("Microphone Active! Speak now.");
            document.getElementById('visualizer').innerText = "(Listening...)";

            inputSource = audioContext.createMediaStreamSource(stream);

            await audioContext.audioWorklet.addModule('data:text/javascript;base64,' + btoa(`
                class PCMProcessor extends AudioWorkletProcessor {
                    process(inputs, outputs, parameters) {
                        const input = inputs[0];
                        if (input.length > 0) {
                            const float32Data = input[0];
                            const int16Data = new Int16Array(float32Data.length);
                            for (let i = 0; i < float32Data.length; i++) {
                                int16Data[i] = Math.max(-1, Math.min(1, float32Data[i])) * 0x7FFF; 
                            }
                            this.port.postMessage(int16Data.buffer);
                        }
                        return true;
                    }
                }
                registerProcessor('pcm-processor', PCMProcessor);
            `));

            processor = new AudioWorkletNode(audioContext, 'pcm-processor');
            inputSource.connect(processor);
            processor.connect(audioContext.destination);

            processor.port.onmessage = (e) => {
                if (websocket && websocket.readyState === WebSocket.OPEN) {
                    websocket.send(e.data);
                }
            };

        } catch (err) {
            console.error("Mic Error:", err);
            logStatus("Mic Error: " + err.message, true);
            stopCall();
        }
    }

    let nextStartTime = 0;
    function playAudioQueue(arrayBuffer) {
        if (!audioContext) return;
        const audioData = new Int16Array(arrayBuffer);
        const floatData = new Float32Array(audioData.length);
        for (let i = 0; i < audioData.length; i++) {
            floatData[i] = audioData[i] / 0x7FFF;
        }

        // 24000 is common for Deepgram Aura voices. If slow, change to 16000.
        const buffer = audioContext.createBuffer(1, floatData.length, 24000); 
        buffer.getChannelData(0).set(floatData);

        const source = audioContext.createBufferSource();
        source.buffer = buffer;
        source.connect(audioContext.destination);

        if (nextStartTime < audioContext.currentTime) nextStartTime = audioContext.currentTime;
        source.start(nextStartTime);
        nextStartTime += buffer.duration;
    }

    function stopCall() {
        if (websocket) websocket.close();
        if (audioContext) audioContext.close();
        document.getElementById('startBtn').disabled = false;
        document.getElementById('stopBtn').style.display = "none";
        logStatus("Disconnected");
        document.getElementById('visualizer').innerText = "(Microphone Inactive)";
    }
</script>
</body>
</html>
